# R---
title: "CODING EA"
output: pdf_document
date: "2025-08-26"
---

# The aim of this study is to quantify the optimization advantages of Evolutionary Algorithms 
# over random search, evaluate whether their core operators (selection, crossover, and mutation) 
# provide performance improvements that justify their algorithmic complexity, and assess the 
# extent to which EA's effectiveness stems from structured search mechanisms versus increased 
# sampling intensity.

```{r}


set.seed(42)
library(stats)  # for optim

# vectorised uniform respecting per-gene bounds
runif_vec <- function(lower, upper) {
  stopifnot(length(lower) == length(upper))
  lower + runif(length(lower)) * (upper - lower)
}

# clamping with vectorization
clamp <- function(x, lo, hi) {
  if (length(lo) == 1) lo <- rep(lo, length(x))
  if (length(hi) == 1) hi <- rep(hi, length(x))
  pmin(pmax(x, lo), hi)
}

# numerically-stable softmax (used for selection)
softmax <- function(x, tau = 1) {
  if (!is.finite(tau) || tau <= 0) stop("tau must be > 0")
  if (all(is.na(x))) return(rep(1/length(x), length(x)))
  z <- (x - max(x, na.rm = TRUE)) / tau
  z <- pmax(z, -500)
  ez <- exp(z)
  s  <- sum(ez, na.rm = TRUE)
  if (!is.finite(s) || s == 0) rep(1/length(x), length(x)) else ez / s
}

# population diagnostics
pop_diversity <- function(P) {
  if (ncol(P) <= 1) return(0)
  centroid  <- rowMeans(P, na.rm = TRUE)
  distances <- sqrt(colSums((P - centroid)^2, na.rm = TRUE))
  mean(distances, na.rm = TRUE)
}

pop_convergence <- function(P) {
  if (ncol(P) <= 1) return(0)
  param_std <- apply(P, 1, sd, na.rm = TRUE)
  mean(param_std, na.rm = TRUE)
}

pop_stats <- function(P, f) {
  list(
    fitness = c(best = max(f, na.rm = TRUE), 
                mean = mean(f, na.rm = TRUE), 
                median = median(f, na.rm = TRUE),
                std = sd(f, na.rm = TRUE),
                q25 = quantile(f, 0.25, na.rm = TRUE),
                q75 = quantile(f, 0.75, na.rm = TRUE)),
    diversity = pop_diversity(P),
    convergence = pop_convergence(P)
  )
}

# Null-coalescing helper
`%||%` <- function(x, y) if (is.null(x)) y else x




```


```{r}

# ===============================================
# 2) Benchmarks (Rastrigin, Rosenbrock) & Toy NN
# ===============================================

# Rastrigin (maximize negative loss form)
rastrigin <- function(x) {
  d <- length(x)
  -(10 * d + sum(x^2 - 10 * cos(2 * pi * x)))
}

# Rosenbrock (negative of the usual loss so we maximize)
rosenbrock <- function(x) {
  d <- length(x)
  -sum(100 * (x[2:d] - x[1:(d-1)]^2)^2 + (1 - x[1:(d-1)])^2)
}

# 2D "moons" dataset generator
make_moons <- function(n = 200, noise = 0.1, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  n1 <- floor(n / 2); n2 <- n - n1
  theta1 <- seq(0, pi, length.out = n1)
  X1 <- cbind(cos(theta1), sin(theta1))
  theta2 <- seq(0, pi, length.out = n2)
  X2 <- cbind(1 - cos(theta2), 1 - sin(theta2) - 0.5)
  X <- rbind(X1, X2)
  X <- X + matrix(rnorm(n * 2, 0, noise), ncol = 2)
  y <- c(rep(0, n1), rep(1, n2))
  list(X = X, y = y)
}

# Tiny NN (2 -> 5 -> 1), sigmoid output; returns helpers
make_nn_classifier <- function(input_dim = 2, hidden_dim = 5, output_dim = 1) {
  n_params <- input_dim * hidden_dim + hidden_dim + 
              hidden_dim * output_dim + output_dim
  
  unpack <- function(theta) {
    idx <- 1
    W1 <- matrix(theta[idx:(idx + input_dim * hidden_dim - 1)], 
                 nrow = hidden_dim, ncol = input_dim)
    idx <- idx + input_dim * hidden_dim
    b1 <- theta[idx:(idx + hidden_dim - 1)]; idx <- idx + hidden_dim
    W2 <- matrix(theta[idx:(idx + hidden_dim * output_dim - 1)],
                 nrow = output_dim, ncol = hidden_dim)
    idx <- idx + hidden_dim * output_dim
    b2 <- theta[idx:(idx + output_dim - 1)]
    list(W1 = W1, b1 = b1, W2 = W2, b2 = b2)
  }
  
  forward <- function(X, theta) {
    p <- unpack(theta); n <- nrow(X)
    Z1 <- X %*% t(p$W1) + matrix(p$b1, n, length(p$b1), byrow = TRUE)
    A1 <- tanh(Z1)
    Z2 <- A1 %*% t(p$W2) + matrix(p$b2, n, length(p$b2), byrow = TRUE)
    1 / (1 + exp(-Z2))  # sigmoid
  }
  
  loss <- function(theta, X, y) {
    pred <- forward(X, theta)
    eps <- 1e-7
    pred <- pmax(pmin(pred, 1 - eps), eps)
    -mean(y * log(pred) + (1 - y) * log(1 - pred))
  }
  
  accuracy <- function(theta, X, y) {
    pred <- forward(X, theta)
    mean((pred > 0.5) == y)
  }
  
  list(n_params = n_params, forward = forward, 
       loss = loss, accuracy = accuracy, unpack = unpack)
}

# backprop gradient (for Adam baseline)
nn_gradient <- function(theta, X, y, nn) {
  n <- nrow(X)
  p <- nn$unpack(theta)
  Z1 <- X %*% t(p$W1) + matrix(p$b1, n, length(p$b1), byrow = TRUE)
  A1 <- tanh(Z1)
  Z2 <- A1 %*% t(p$W2) + matrix(p$b2, n, length(p$b2), byrow = TRUE)
  A2 <- 1 / (1 + exp(-Z2))
  dZ2 <- (A2 - y) / n
  dW2 <- t(dZ2) %*% A1
  db2 <- colSums(dZ2)
  dA1 <- dZ2 %*% p$W2
  dZ1 <- dA1 * (1 - A1^2)
  dW1 <- t(dZ1) %*% X
  db1 <- colSums(dZ1)
  c(as.vector(dW1), db1, as.vector(dW2), db2)
}




```


```{r}

# =====================================
# 3) Evolutionary Algorithm (EA core)
# =====================================

validate_ea_params <- function(fitness_fn, dim, lower, upper, pop_size, gens, 
                               pcross, elitism, patience, eval_budget) {
  stopifnot(
    is.function(fitness_fn),
    is.numeric(dim) && length(dim) == 1 && dim > 0,
    is.numeric(pop_size) && pop_size > 0,
    is.numeric(gens) && gens > 0,
    is.numeric(pcross) && pcross >= 0 && pcross <= 1,
    is.numeric(elitism) && elitism >= 0 && elitism < pop_size,
    is.numeric(patience) && patience > 0,
    is.numeric(eval_budget) && eval_budget > 0
  )
  lower <- rep(lower, length.out = dim)
  upper <- rep(upper, length.out = dim)
  if (any(upper <= lower)) stop("All upper bounds must be > lower bounds")
  
  test_point <- runif_vec(lower, upper)
  test_fitness <- tryCatch(
    fitness_fn(test_point),
    error = function(e) stop(paste("Fitness function error:", e$message))
  )
  if (!is.numeric(test_fitness) || length(test_fitness) != 1 || !is.finite(test_fitness)) {
    stop("Fitness function must return a single finite numeric value")
  }
  list(lower = lower, upper = upper)
}

select_parent <- function(f, mode = c("tournament","proportionate","rank"),
                          k = 3, tau = 1) {
  mode <- match.arg(mode)
  n <- length(f); if (n == 1) return(1)
  switch(
    mode,
    "proportionate" = {
      probs <- softmax(f - max(f, na.rm = TRUE), tau = tau)
      sample.int(n, 1, prob = probs)
    },
    "tournament" = {
      k <- min(k, n); idx <- sample.int(n, k); idx[which.max(f[idx])]
    },
    "rank" = {
      ranks <- rank(f, ties.method = "random")
      probs <- ranks / sum(ranks)
      sample.int(n, 1, prob = probs)
    }
  )
}

crossover_single_point <- function(pa, pb) {
  d <- length(pa); if (d == 1L) return((pa + pb)/2)
  q <- sample.int(d - 1, 1)
  c(pa[1:q], pb[(q + 1):d])
}

crossover_blx <- function(pa, pb, alpha = 0.5) {
  lo <- pmin(pa, pb); hi <- pmax(pa, pb); I <- hi - lo
  runif(length(pa), lo - alpha * I, hi + alpha * I)
}

crossover_sbx <- function(pa, pb, lower, upper, eta_c = 10) {
  d <- length(pa); u <- runif(d)
  beta <- ifelse(u <= 0.5, (2*u)^(1/(eta_c+1)), (1/(2*(1-u)))^(1/(eta_c+1)))
  c1 <- 0.5 * ((1 + beta) * pa + (1 - beta) * pb)
  c2 <- 0.5 * ((1 - beta) * pa + (1 + beta) * pb)
  child <- if (runif(1) < 0.5) c1 else c2
  clamp(child, lower, upper)
}

mutate_gaussian <- function(x, sigma_vec, pm = NULL) {
  d <- length(x); if (is.null(pm)) pm <- 1/d
  mask <- runif(d) < pm
  if (any(mask)) x[mask] <- x[mask] + rnorm(sum(mask), 0, sigma_vec[mask])
  x
}

mutate_poly <- function(x, lower, upper, eta_m = 20, pm = NULL) {
  d <- length(x); if (is.null(pm)) pm <- 1/d
  lo <- rep(lower, length.out = d); hi <- rep(upper, length.out = d)
  rng <- hi - lo; if (any(rng <= 0)) stop("upper must be > lower for all genes")
  y <- (x - lo) / rng; mask <- runif(d) < pm
  if (!any(mask)) return(x)
  u <- runif(d); mut_pow <- 1 / (eta_m + 1); deltaq <- numeric(d)
  idx <- which(mask)
  for (i in idx) {
    delta1 <- y[i]; delta2 <- 1 - y[i]
    if (u[i] <= 0.5) {
      xy <- 1 - delta1; val <- 2*u[i] + (1-2*u[i])*(xy^(eta_m+1))
      deltaq[i] <- (val^mut_pow) - 1
    } else {
      xy <- 1 - delta2; val <- 2*(1-u[i]) + 2*(u[i]-0.5)*(xy^(eta_m+1))
      deltaq[i] <- 1 - (val^mut_pow)
    }
  }
  y_new <- clamp(y + deltaq, 0, 1); out <- lo + y_new * rng
  out[!mask] <- x[!mask]; clamp(out, lo, hi)
}

evolve_real_enhanced <- function(
  fitness_fn, dim, lower, upper,
  pop_size = 100, gens = 200,
  selection = c("tournament", "proportionate", "rank"),
  tournament_k = 3, tau = 1,
  crossover = c("sbx", "blx", "single"),
  alpha = 0.5, eta_c = 10, pcross = 0.9,
  mutation = c("poly", "gaussian"),
  mut_sd0 = 0.2, mut_sd_min = 1e-3, mut_sd_decay = 0.95,
  eta_m = 20, pmutation = NULL,
  elitism = 2, beta_replace = 0.0,
  eval_budget = Inf, patience = 30, min_delta = 1e-8,
  log_freq = 10, verbose = TRUE, seed = NULL,
  track_evals = TRUE
) {
  if (!is.null(seed)) {
    old_seed <- NULL
    if (exists(".Random.seed", .GlobalEnv)) old_seed <- .Random.seed
    on.exit({ if (!is.null(old_seed)) .Random.seed <<- old_seed }, add = TRUE)
    set.seed(seed)
  }
  selection <- match.arg(selection)
  crossover  <- match.arg(crossover)
  mutation   <- match.arg(mutation)
  bounds <- validate_ea_params(fitness_fn, dim, lower, upper, pop_size, gens,
                               pcross, elitism, patience, eval_budget)
  lower <- bounds$lower; upper <- bounds$upper; range <- upper - lower
  
  # init population
  P <- sapply(1:pop_size, function(i) runif_vec(lower, upper))
  f <- apply(P, 2, fitness_fn)
  if (!all(is.finite(f))) stop("Non-finite fitness values at initialization")
  evals <- pop_size
  
  # tracking
  best_idx <- which.max(f)
  best <- list(f = f[best_idx], theta = P[, best_idx], generation = 0)
  if (track_evals) {
    eval_history <- data.frame(evaluations = 1:pop_size, best_so_far = cummax(f))
  }
  hist <- data.frame(
    generation = integer(gens + 1),
    best = numeric(gens + 1),
    mean = numeric(gens + 1),
    median = numeric(gens + 1),
    diversity = numeric(gens + 1),
    mut_sd = numeric(gens + 1)
  )
  stats <- pop_stats(P, f)
  hist[1, ] <- c(0, stats$fitness["best"], stats$fitness["mean"], 
                 stats$fitness["median"], stats$diversity, mut_sd0)
  if (verbose) cat(sprintf("Gen %3d | best=%.6f | mean=%.6f | diversity=%.4f\n",
                           0, best$f, stats$fitness["mean"], stats$diversity))
  
  no_improve <- 0L; stop_reason <- "gens_exhausted"; mut_sd <- mut_sd0
  
  for (g in 1:gens) {
    if (evals >= eval_budget) { stop_reason <- "eval_budget"; break }
    mut_sd <- max(mut_sd_min, mut_sd * mut_sd_decay)
    sigma_vec <- mut_sd * range
    
    elite_idx <- order(f, decreasing = TRUE)[1:elitism]
    elites    <- P[, elite_idx, drop = FALSE]
    elites_f  <- f[elite_idx]
    
    n_off <- pop_size - elitism
    Off <- matrix(NA_real_, nrow = dim, ncol = n_off)
    for (k in 1:n_off) {
      i <- select_parent(f, selection, tournament_k, tau)
      j <- select_parent(f, selection, tournament_k, tau)
      pa <- P[, i]; pb <- P[, j]
      if (runif(1) < pcross) {
        child <- switch(crossover,
          "sbx"    = crossover_sbx(pa, pb, lower, upper, eta_c),
          "blx"    = crossover_blx(pa, pb, alpha),
          "single" = crossover_single_point(pa, pb))
      } else child <- if (runif(1) < 0.5) pa else pb
      child <- switch(mutation,
        "gaussian" = mutate_gaussian(child, sigma_vec, pm = pmutation),
        "poly"     = mutate_poly(child, lower, upper, eta_m = eta_m, pm = pmutation))
      if (runif(1) < beta_replace) child <- runif_vec(lower, upper)
      Off[, k] <- clamp(child, lower, upper)
    }
    f_off <- apply(Off, 2, fitness_fn)
    if (!all(is.finite(f_off))) stop("Non-finite fitness in offspring")
    evals <- evals + n_off
    
    if (track_evals) {
      last_best <- tail(eval_history$best_so_far, 1)
      for (i in 1:n_off) {
        last_best <- max(last_best, f_off[i])
        eval_history <- rbind(
          eval_history,
          data.frame(evaluations = nrow(eval_history) + 1, best_so_far = last_best)
        )
      }
    }
    
    P <- cbind(elites, Off)
    f <- c(elites_f, f_off)
    stats <- pop_stats(P, f)
    b <- stats$fitness["best"]
    hist[g + 1, ] <- c(g, b, stats$fitness["mean"], stats$fitness["median"], stats$diversity, mut_sd)
    
    if (b > best$f + min_delta) {
      best <- list(f = b, theta = P[, which.max(f)], generation = g)
      no_improve <- 0L
    } else no_improve <- no_improve + 1L
    if (no_improve >= patience) { stop_reason <- "early_stopping"; break }
    if (verbose && (g %% log_freq == 0L)) {
      cat(sprintf("Gen %3d | best=%.6f | mean=%.6f | diversity=%.4f\n",
                  g, b, stats$fitness["mean"], stats$diversity))
    }
  }
  history <- hist[1:(g + 1), ]
  history$evaluations <- (0:g) * (pop_size - elitism) + pop_size
  
  result <- list(
    best_fit = best$f, best_theta = best$theta, best_generation = best$generation,
    history = history, final_population = P, final_fitness = f,
    evaluations = evals, stop_reason = stop_reason, method = "EA"
  )
  if (track_evals) result$eval_history <- eval_history
  result
}



```


```{r}

# ==========================================
# 4) Baselines: BSRS, PSO, GD, Adam, BFGS, Nelder-mead
# ==========================================

# Pure random search (BSRS)
bsrs <- function(fitness_fn, dim, lower, upper, eval_budget = 10000, 
                 verbose = FALSE, track_evals = TRUE) {
  best_f <- -Inf; best_theta <- NULL
  lower <- rep(lower, length.out = dim); upper <- rep(upper, length.out = dim)
  eval_history <- if (track_evals) data.frame(evaluations = integer(), best_so_far = numeric()) else NULL
  for (i in 1:eval_budget) {
    theta <- runif_vec(lower, upper); f <- fitness_fn(theta)
    if (f > best_f) { best_f <- f; best_theta <- theta }
    if (track_evals) eval_history <- rbind(eval_history, data.frame(evaluations = i, best_so_far = best_f))
  }
  out <- list(best_fit = best_f, best_theta = best_theta, method = "Random", evaluations = eval_budget)
  if (track_evals) out$eval_history <- eval_history
  out
}

# Particle Swarm Optimization (with linear inertia schedule)
pso <- function(fitness_fn, dim, lower, upper, 
                swarm_size = 30, max_iter = 200,
                w = 0.7, c1 = 1.5, c2 = 1.5,
                eval_budget = Inf, verbose = FALSE,
                track_evals = TRUE, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  lower <- rep(lower, length.out = dim); upper <- rep(upper, length.out = dim)
  range <- upper - lower; vmax <- 0.2 * range
  X <- sapply(1:swarm_size, function(i) runif_vec(lower, upper))
  V <- matrix(0, nrow = dim, ncol = swarm_size)
  f <- apply(X, 2, fitness_fn); evals <- swarm_size
  pbest <- X; pbest_f <- f
  gbest_idx <- which.max(f); gbest <- X[, gbest_idx]; gbest_f <- f[gbest_idx]
  eval_history <- if (track_evals) data.frame(evaluations = 1:swarm_size, best_so_far = cummax(f)) else NULL
  w0 <- w; w_end <- 0.3
  
  for (iter in 1:max_iter) {
    if (evals >= eval_budget) break
    w <- w0 + (w_end - w0) * (iter / max_iter)
    for (i in 1:swarm_size) {
      r1 <- runif(dim); r2 <- runif(dim)
      V[, i] <- w * V[, i] + c1 * r1 * (pbest[, i] - X[, i]) + c2 * r2 * (gbest - X[, i])
      V[, i] <- clamp(V[, i], -vmax, vmax)
      X[, i] <- clamp(X[, i] + V[, i], lower, upper)
    }
    f <- apply(X, 2, fitness_fn); evals <- evals + swarm_size
    better <- f > pbest_f; pbest[, better] <- X[, better]; pbest_f[better] <- f[better]
    best_idx <- which.max(pbest_f)
    if (pbest_f[best_idx] > gbest_f) { gbest <- pbest[, best_idx]; gbest_f <- pbest_f[best_idx] }
    if (track_evals) {
      for (i in 1:swarm_size) {
        eval_history <- rbind(eval_history, data.frame(evaluations = nrow(eval_history) + 1, best_so_far = gbest_f))
      }
    }
    if (verbose && iter %% 10 == 0) cat(sprintf("PSO Iter %3d | best=%.6f\n", iter, gbest_f))
  }
  out <- list(best_fit = gbest_f, best_theta = gbest, method = "PSO", evaluations = evals)
  if (track_evals) out$eval_history <- eval_history
  out
}

# Fixed gradient descent with consistent evaluation counting
gradient_descent_fd_fixed <- function(fitness_fn, dim, lower, upper,
                                     x0 = NULL, lr = 0.01, momentum = 0.9,
                                     eval_budget = 5000, verbose = FALSE,
                                     track_evals = TRUE, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  lower <- rep(lower, length.out = dim)
  upper <- rep(upper, length.out = dim)
  range <- upper - lower
  
  if (is.null(x0)) x0 <- runif_vec(lower, upper)
  x <- x0
  v <- rep(0, dim)
  
  best_x <- x
  best_f <- fitness_fn(x)
  evals <- 1
  
  eval_history <- if (track_evals) {
    data.frame(evaluations = 1, best_so_far = best_f)
  } else NULL
  
  iter <- 1
  while (evals < eval_budget) {
    # Calculate gradient using finite differences
    grad <- numeric(dim)
    gradient_evals <- 0
    
    for (i in 1:dim) {
      if (evals + gradient_evals + 2 > eval_budget) break
      
      h <- max(1e-6, 1e-4 * range[i])
      xm <- x; xp <- x
      xm[i] <- max(lower[i], x[i] - h)
      xp[i] <- min(upper[i], x[i] + h)
      
      fm <- fitness_fn(xm)
      fp <- fitness_fn(xp)
      gradient_evals <- gradient_evals + 2
      
      grad[i] <- (fp - fm) / (xp[i] - xm[i] + 1e-12)
    }
    
    evals <- evals + gradient_evals
    if (evals >= eval_budget) break
    
    # Update position
    v <- momentum * v + lr * grad
    x <- clamp(x + v, lower, upper)
    
    # Evaluate current position
    f_current <- fitness_fn(x)
    evals <- evals + 1
    
    if (f_current > best_f) {
      best_f <- f_current
      best_x <- x
    }
    
    if (track_evals) {
      eval_history <- rbind(eval_history, 
                           data.frame(evaluations = evals, best_so_far = best_f))
    }
    
    if (verbose && iter %% 50 == 0) {
      cat(sprintf("GD Iter %3d | current=%.6f | best=%.6f | evals=%d\n", 
                  iter, f_current, best_f, evals))
    }
    
    iter <- iter + 1
  }
  
  out <- list(
    best_fit = best_f,
    best_theta = best_x,
    method = "GD",
    evaluations = evals
  )
  if (track_evals) out$eval_history <- eval_history
  return(out)
}

# Adam (gradient ascent). Supply grad_fn and (optional) eval_fn for tracking.
adam <- function(grad_fn, x0, lr = 0.001, beta1 = 0.9, beta2 = 0.999,
                 epsilon = 1e-8, max_iter = 1000, eval_fn = NULL,
                 lower = -Inf, upper = Inf, verbose = FALSE,
                 track_evals = TRUE) {
  x <- x0; m <- rep(0, length(x)); v <- rep(0, length(x))
  best_x <- x; best_f <- if (!is.null(eval_fn)) eval_fn(x) else NA
  eval_history <- if (track_evals && !is.null(eval_fn)) data.frame(iterations = 0, value = best_f) else NULL
  for (t in 1:max_iter) {
    grad <- grad_fn(x)
    m <- beta1 * m + (1 - beta1) * grad
    v <- beta2 * v + (1 - beta2) * grad^2
    m_hat <- m / (1 - beta1^t)
    v_hat <- v / (1 - beta2^t)
    x <- clamp(x + lr * m_hat / (sqrt(v_hat) + epsilon), lower, upper)
    if (!is.null(eval_fn)) {
      f_current <- eval_fn(x)
      if (is.na(best_f) || f_current > best_f) { best_f <- f_current; best_x <- x }
      if (track_evals) eval_history <- rbind(eval_history, data.frame(iterations = t, value = f_current))
      if (verbose && t %% 100 == 0) cat(sprintf("Adam Iter %3d | current=%.6f | best=%.6f\n", t, f_current, best_f))
    }
  }
  out <- list(best_theta = best_x, best_fit = best_f, method = "Adam", iterations = max_iter)
  if (track_evals && !is.null(eval_fn)) out$eval_history <- eval_history
  out
}

# Enhanced L-BFGS-B with proper evaluation tracking
lbfgsb_baseline <- function(fitness_fn, dim, lower, upper, eval_budget = 5000, 
                           track_evals = TRUE, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  # Counter for function evaluations
  eval_count <- 0
  best_f <- -Inf
  eval_history <- if (track_evals) data.frame(evaluations = integer(), best_so_far = numeric()) else NULL
  
  # Wrapper function to count evaluations
  tracked_fitness <- function(theta) {
    eval_count <<- eval_count + 1
    f <- fitness_fn(theta)
    if (f > best_f) best_f <<- f
    if (track_evals) {
      eval_history <<- rbind(eval_history, 
                            data.frame(evaluations = eval_count, best_so_far = best_f))
    }
    return(-f)  # Minimize negative for maximization
  }
  
  # Run optimization with evaluation budget constraint
  result <- tryCatch({
    optim(
      par = runif_vec(rep(lower, length.out = dim), rep(upper, length.out = dim)),
      fn = function(theta) {
        if (eval_count >= eval_budget) stop("Budget exceeded")
        tracked_fitness(theta)
      },
      method = "L-BFGS-B",
      lower = rep(lower, length.out = dim),
      upper = rep(upper, length.out = dim),
      control = list(maxit = eval_budget)
    )
  }, error = function(e) {
    if (grepl("Budget exceeded", e$message)) {
      list(value = -best_f, par = rep(NA, dim), convergence = 1)
    } else {
      stop(e)
    }
  })
  
  out <- list(
    best_fit = best_f,
    best_theta = if (all(is.na(result$par))) rep(NA, dim) else result$par,
    method = "L-BFGS-B",
    evaluations = eval_count,
    convergence = result$convergence
  )
  if (track_evals) out$eval_history <- eval_history
  return(out)
}

# Enhanced Nelder-Mead with evaluation tracking
nelder_mead_baseline <- function(fitness_fn, dim, lower, upper, eval_budget = 5000,
                                track_evals = TRUE, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  eval_count <- 0
  best_f <- -Inf
  eval_history <- if (track_evals) data.frame(evaluations = integer(), best_so_far = numeric()) else NULL
  
  tracked_fitness <- function(theta) {
    eval_count <<- eval_count + 1
    # Clamp to bounds (Nelder-Mead doesn't handle bounds natively)
    theta <- clamp(theta, rep(lower, length.out = dim), rep(upper, length.out = dim))
    f <- fitness_fn(theta)
    if (f > best_f) best_f <<- f
    if (track_evals) {
      eval_history <<- rbind(eval_history, 
                            data.frame(evaluations = eval_count, best_so_far = best_f))
    }
    return(-f)  # Minimize negative
  }
  
  result <- tryCatch({
    optim(
      par = runif_vec(rep(lower, length.out = dim), rep(upper, length.out = dim)),
      fn = function(theta) {
        if (eval_count >= eval_budget) stop("Budget exceeded")
        tracked_fitness(theta)
      },
      method = "Nelder-Mead",
      control = list(maxit = eval_budget)
    )
  }, error = function(e) {
    if (grepl("Budget exceeded", e$message)) {
      list(value = -best_f, par = rep(NA, dim), convergence = 1)
    } else {
      stop(e)
    }
  })
  
  out <- list(
    best_fit = best_f,
    best_theta = if (all(is.na(result$par))) rep(NA, dim) else result$par,
    method = "Nelder-Mead", 
    evaluations = eval_count
  )
  if (track_evals) out$eval_history <- eval_history
  return(out)
}








```


```{r}

# =======================================================
# 5) Benchmark harness, statistics, effect sizes & plots
# =======================================================

make_result_entry <- function(method, run, res) {
  list(
    method = method,
    run = run,
    best_fit = res$best_fit,
    evaluations = res$evaluations %||% NA_integer_,
    eval_history = res$eval_history %||% NULL
  )
}

benchmark_optimizers <- function(
  fitness_fn, dim, lower, upper,
  methods = c("EA", "PSO", "GD", "Random", "L-BFGS-B"),
  n_runs = 30, eval_budget = 5000,
  verbose = TRUE, seed_base = 1000,
  ...
) {
  results <- list()
  for (run in 1:n_runs) {
    if (verbose) cat(sprintf("\n=== Run %d/%d ===\n", run, n_runs))
    run_seed <- seed_base + run
    set.seed(run_seed)
    
    if ("EA" %in% methods) {
      if (verbose) cat("Running EA...\n")
      ea_result <- evolve_real_enhanced(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        pop_size = 50, gens = floor(eval_budget / 50),
        eval_budget = eval_budget,
        verbose = FALSE, seed = run_seed,
        track_evals = TRUE,
        ...
      )
      results[[length(results) + 1]] <- make_result_entry("EA", run, ea_result)
    }
    if ("PSO" %in% methods) {
      if (verbose) cat("Running PSO...\n")
      pso_result <- pso(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        swarm_size = 30, max_iter = floor(eval_budget / 30),
        eval_budget = eval_budget,
        verbose = FALSE, seed = run_seed,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("PSO", run, pso_result)
    }
    if ("GD" %in% methods) {
      if (verbose) cat("Running Gradient Descent...\n")
      gd_result <- gradient_descent_fd_fixed(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        eval_budget = eval_budget,
        verbose = FALSE, seed = run_seed,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("GD", run, gd_result)
    }
    if ("Random" %in% methods) {
      if (verbose) cat("Running Random Search...\n")
      rs_result <- bsrs(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        eval_budget = eval_budget,
        verbose = FALSE,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("Random", run, rs_result)
    }
    if ("L-BFGS-B" %in% methods) {
  if (verbose) cat("Running L-BFGS-B...\n")
  lb_result <- lbfgsb_baseline(
    fitness_fn = fitness_fn,
    dim = dim, lower = lower, upper = upper,
    eval_budget = eval_budget
  )
  results[[length(results) + 1]] <- make_result_entry("L-BFGS-B", run, lb_result)
}

  }
  results
}

compute_statistics <- function(results) {
  df <- data.frame(
    method = sapply(results, function(x) x$method),
    run = sapply(results, function(x) x$run),
    best_fit = sapply(results, function(x) x$best_fit),
    evaluations = sapply(results, function(x) x$evaluations)
  )
  aggregate(best_fit ~ method, data = df, FUN = function(x) {
    c(mean = mean(x), median = median(x), sd = sd(x),
      min = min(x), max = max(x), q25 = quantile(x, 0.25), q75 = quantile(x, 0.75))
  })
}

# Cliff's Delta effect size
cliffs_delta <- function(x, y) {
  n1 <- length(x); n2 <- length(y); dominance <- 0
  for (i in 1:n1) for (j in 1:n2) {
    if (x[i] > y[j]) dominance <- dominance + 1
    else if (x[i] < y[j]) dominance <- dominance - 1
  }
  delta <- dominance / (n1 * n2)
  magnitude <- if (abs(delta) < 0.147) "negligible"
  else if (abs(delta) < 0.33) "small"
  else if (abs(delta) < 0.474) "medium"
  else "large"
  list(delta = delta, magnitude = magnitude)
}

# Sample-efficiency curves (best-so-far vs evaluations)
plot_sample_efficiency <- function(results, title = "Sample Efficiency Comparison") {
  methods <- unique(sapply(results, `[[`, "method"))
  cols <- c("EA"="blue","PSO"="red","GD"="green","Random"="gray","Adam"="purple", "L-BFGS-B"="orange")
  cols <- cols[names(cols) %in% methods]
  
  xmax <- max(sapply(results, function(x) {
    if (!is.null(x$eval_history)) {
      if ("evaluations" %in% names(x$eval_history)) max(x$eval_history$evaluations)
      else max(x$eval_history$iterations)
    } else x$evaluations
  }), na.rm = TRUE)
  # infer y-range from histories or final fits
  yvals <- c(
    unlist(lapply(results, function(x) if (!is.null(x$eval_history) && "best_so_far" %in% names(x$eval_history)) x$eval_history$best_so_far)),
    sapply(results, function(x) x$best_fit)
  )
  ymin <- min(yvals, na.rm = TRUE); ymax <- max(yvals, na.rm = TRUE)
  
  plot(NA, xlim = c(0, xmax), ylim = c(ymin, ymax),
       xlab = "Evaluations", ylab = "Best-so-far Fitness", main = title)
  
  # light per-run traces
  lapply(results, function(r) {
    if (!is.null(r$eval_history)) {
      if ("evaluations" %in% names(r$eval_history) && "best_so_far" %in% names(r$eval_history)) {
        lines(r$eval_history$evaluations, r$eval_history$best_so_far,
              col = adjustcolor(cols[r$method], 0.3), lwd = 0.7)
      }
    }
  })
  
  # mean curves
  for (m in methods) {
    rs <- results[sapply(results, function(x) x$method == m)]
    rs <- rs[!sapply(rs, function(x) is.null(x$eval_history))]
    if (length(rs) == 0) next
    if (!all(sapply(rs, function(x) "evaluations" %in% names(x$eval_history)))) next
    all_e <- sort(unique(unlist(lapply(rs, function(x) x$eval_history$evaluations))))
    mean_curve <- sapply(all_e, function(e) {
      vals <- sapply(rs, function(x) {
        idx <- which(x$eval_history$evaluations <= e)
        if (length(idx)) x$eval_history$best_so_far[max(idx)] else NA_real_
      })
      mean(vals, na.rm = TRUE)
    })
    lines(all_e, mean_curve, col = cols[m], lwd = 2)
  }
  legend("bottomright", legend = names(cols), col = cols, lwd = 2)
}





```


```{r}

# ======================================
# 6) Ablation (what EA parts matter?)
# ======================================

ablation_study <- function(fitness_fn, dim, lower, upper, 
                           n_runs = 10, eval_budget = 5000,
                           verbose = TRUE) {
  configs <- list(
    "Full EA"       = list(pcross=0.9, mutation="poly", selection="tournament"),
    "No Crossover"  = list(pcross=0.0, mutation="poly", selection="tournament"),
    "No Mutation"   = list(pcross=0.9, mutation="poly", selection="tournament", mut_sd0=0, pmutation=0),
    "Random Select" = list(pcross=0.9, mutation="poly", selection="proportionate", tau=1e10),
    "Mutation Only" = list(pcross=0.0, mutation="poly", selection="proportionate", tau=1e10)
  )
  rows <- list()
  for (cfg in names(configs)) {
    if (verbose) cat("\nTesting:", cfg, "\n")
    pars <- configs[[cfg]]
    for (run in 1:n_runs) {
      res <- evolve_real_enhanced(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        pop_size = 50, gens = floor(eval_budget / 50),
        eval_budget = eval_budget,
        pcross   = pars$pcross,
        mutation = pars$mutation,
        selection= pars$selection,
        tau      = pars$tau      %||% 1,
        mut_sd0  = pars$mut_sd0  %||% 0.2,
        pmutation= pars$pmutation%||% NULL,
        verbose  = FALSE,
        seed     = 5000 + run
      )
      rows[[length(rows) + 1]] <- data.frame(config = cfg, run = run, best_fit = res$best_fit)
    }
  }
  do.call(rbind, rows)
}

summarize_ablation <- function(raw_df) {
  aggregate(best_fit ~ config, data = raw_df, function(x)
    c(mean=mean(x), sd=sd(x), median=median(x)))
}







```


```{r}
# ==========================================
# 7) Demos to run for thesis figures/tables
# ==========================================

demo_rastrigin_comparison <- function(n_runs = 20, eval_budget = 5000) {
  cat("\n=== Rastrigin Function Benchmark ===\n")
  results <- benchmark_optimizers_fixed(
    fitness_fn = rastrigin,
    dim = 10, lower = -5.12, upper = 5.12,
    methods = c("EA", "PSO", "GD", "Random", "L-BFGS-B", "Nelder-Mead"),
    n_runs = n_runs, eval_budget = eval_budget, verbose = TRUE
  )
  stats <- compute_statistics(results); print(stats)

  cat("\n=== Effect Sizes (Cliff's Delta: EA vs others) ===\n")
  ea_fits <- sapply(results[sapply(results, function(x) x$method == "EA")],
                    function(x) x$best_fit)
  for (method in c("PSO", "GD", "Random", "L-BFGS-B", "Nelder-Mead")) {
    method_fits <- sapply(results[sapply(results, function(x) x$method == method)],
                          function(x) x$best_fit)
    effect <- cliffs_delta(ea_fits, method_fits)
    cat(sprintf("EA vs %s: δ = %.3f (%s)\n", method, effect$delta, effect$magnitude))
  }

  par(mfrow = c(1, 2))
  df <- data.frame(method = sapply(results, `[[`, "method"),
                   best_fit = sapply(results, `[[`, "best_fit"))
  boxplot(best_fit ~ method, data = df,
          main = "Rastrigin Optimization Results",
          ylab = "Best Fitness (higher is better)")
  plot_sample_efficiency(results, "Sample Efficiency on Rastrigin")
  par(mfrow = c(1, 1))
  invisible(results)
}

# B) Rosenbrock comparison (swap fitness)
demo_rosenbrock_comparison <- function(n_runs = 20, eval_budget = 5000) {
  cat("\n=== Rosenbrock Function Benchmark ===\n")
  results <- benchmark_optimizers_fixed(
    fitness_fn = rosenbrock,
    dim = 10, lower = -5, upper = 5,
    methods = c("EA", "PSO", "GD", "Random", "L-BFGS-B", "Nelder-Mead"),
    n_runs = n_runs, eval_budget = eval_budget, verbose = TRUE
  )
  stats <- compute_statistics(results); print(stats)

  cat("\n=== Effect Sizes (Cliff's Delta: EA vs others) ===\n")
  ea_fits <- sapply(results[sapply(results, function(x) x$method == "EA")],
                    function(x) x$best_fit)
  for (method in c("PSO", "GD", "Random", "L-BFGS-B", "Nelder-Mead")) {
    method_fits <- sapply(results[sapply(results, function(x) x$method == method)],
                          function(x) x$best_fit)
    effect <- cliffs_delta(ea_fits, method_fits)
    cat(sprintf("EA vs %s: δ = %.3f (%s)\n", method, effect$delta, effect$magnitude))
  }

  par(mfrow = c(1, 2))
  df <- data.frame(method = sapply(results, `[[`, "method"),
                   best_fit = sapply(results, `[[`, "best_fit"))
  boxplot(best_fit ~ method, data = df,
          main = "Rosenbrock Optimization Results",
          ylab = "Best Fitness (higher is better)")
  plot_sample_efficiency(results, "Sample Efficiency on Rosenbrock")
  par(mfrow = c(1, 1))
  invisible(results)
}


# C) ML classification demo: NN on moons (EA vs Adam vs Random)
demo_ml_task <- function(n = 200, noise = 0.2, seed = 42) {
  cat("\n=== ML Classification Task (2D Moons) ===\n")
  data <- make_moons(n = n, noise = noise, seed = seed)
  nn <- make_nn_classifier(input_dim = 2, hidden_dim = 5, output_dim = 1)
  fitness_fn <- function(theta) -nn$loss(theta, data$X, data$y)
  grad_fn    <- function(theta) -nn_gradient(theta, data$X, data$y, nn)
  
  results <- list()
  cat("Training with EA...\n")
  ea_result <- evolve_real_enhanced(
    fitness_fn = fitness_fn,
    dim = nn$n_params, lower = -2, upper = 2,
    pop_size = 50, gens = 100,
    verbose = FALSE, seed = seed
  )
  ea_result$accuracy <- nn$accuracy(ea_result$best_theta, data$X, data$y)
  results$EA <- ea_result
  
  cat("Training with Adam...\n")
  x0 <- runif(nn$n_params, -0.5, 0.5)
  adam_result <- adam(
    grad_fn = grad_fn, x0 = x0, lr = 0.01, max_iter = 5000,
    eval_fn = fitness_fn, lower = -2, upper = 2, verbose = FALSE
  )
  adam_result$accuracy <- nn$accuracy(adam_result$best_theta, data$X, data$y)
  results$Adam <- adam_result
  
  cat("Training with Random Search...\n")
  rs_result <- bsrs(
    fitness_fn = fitness_fn, dim = nn$n_params, lower = -2, upper = 2,
    eval_budget = 5000, verbose = FALSE
  )
  rs_result$accuracy <- nn$accuracy(rs_result$best_theta, data$X, data$y)
  results$Random <- rs_result
  
  cat("\n=== Results ===\n")
  cat(sprintf("EA:     Loss = %.4f, Acc = %.2f%%\n", -results$EA$best_fit,    results$EA$accuracy * 100))
  cat(sprintf("Adam:   Loss = %.4f, Acc = %.2f%%\n", -results$Adam$best_fit,  results$Adam$accuracy * 100))
  cat(sprintf("Random: Loss = %.4f, Acc = %.2f%%\n", -results$Random$best_fit,results$Random$accuracy * 100))
  
  plot(data$X, col = data$y + 2, pch = 19,
       main = "2D Moons (colored by class)", xlab = "X1", ylab = "X2")
  legend("topright", c("Class 0", "Class 1"), col = c(2, 3), pch = 19)
  invisible(results)
}

# D) Ablation demo (which EA parts matter?)
demo_ablation <- function(n_runs = 10, eval_budget = 3000) {
  cat("\n=== EA Ablation Study (Rastrigin, d=5) ===\n")
  raw <- ablation_study(
    fitness_fn = rastrigin,
    dim = 5, lower = -5.12, upper = 5.12,
    n_runs = n_runs, eval_budget = eval_budget, verbose = TRUE
  )
  print(summarize_ablation(raw))
  boxplot(best_fit ~ config, data = raw, las = 2,
          main = "EA Component Ablation", ylab = "Best Fitness (higher is better)")
  invisible(raw)
}


```


```{r}

# ======================================================
# 8) Optional: Minimal NSGA-II (for multi-objective)
# ======================================================

dominates <- function(a, b) { all(a >= b) && any(a > b) }

fast_non_dominated_sort <- function(objectives) {
  n <- nrow(objectives)
  S <- vector("list", n); n_dom <- rep(0, n); rank <- rep(0, n); fronts <- list()
  for (i in 1:n) for (j in 1:n) if (i != j) {
    if (dominates(objectives[i,], objectives[j,])) S[[i]] <- c(S[[i]], j)
    else if (dominates(objectives[j,], objectives[i,])) n_dom[i] <- n_dom[i] + 1
  }
  front1 <- which(n_dom == 0); rank[front1] <- 1; fronts[[1]] <- front1
  k <- 1
  while (length(fronts[[k]]) > 0) {
    Q <- c()
    for (i in fronts[[k]]) if (length(S[[i]]) > 0) for (j in S[[i]]) {
      n_dom[j] <- n_dom[j] - 1; if (n_dom[j] == 0) { rank[j] <- k + 1; Q <- c(Q, j) }
    }
    k <- k + 1; if (length(Q) > 0) fronts[[k]] <- Q else break
  }
  list(rank = rank, fronts = fronts)
}

crowding_distance <- function(objectives, front) {
  if (length(front) <= 2) return(rep(Inf, length(front)))
  m <- ncol(objectives); n <- length(front); distance <- rep(0, n)
  for (obj in 1:m) {
    vals <- objectives[front, obj]; ord <- order(vals)
    distance[ord[1]] <- Inf; distance[ord[n]] <- Inf
    range_obj <- max(vals) - min(vals)
    if (n > 2 && range_obj > 0) for (i in 2:(n-1)) {
      distance[ord[i]] <- distance[ord[i]] + (vals[ord[i+1]] - vals[ord[i-1]]) / range_obj
    }
  }
  distance
}

nsga2 <- function(
  fitness_fn, dim, lower, upper,
  pop_size = 100, gens = 100, pcross = 0.9, pmutation = NULL,
  eta_c = 20, eta_m = 20, verbose = TRUE, seed = NULL, track_evals = TRUE
) {
  if (!is.null(seed)) set.seed(seed)
  lower <- rep(lower, length.out = dim); upper <- rep(upper, length.out = dim)
  P <- sapply(1:pop_size, function(i) runif_vec(lower, upper))
  objectives <- t(sapply(apply(P, 2, fitness_fn), unlist)); evals <- pop_size
  eval_history <- if (track_evals) data.frame(evaluations = 1:pop_size, best_obj1 = cummax(objectives[,1])) else NULL
  history <- list()
  
  for (g in 1:gens) {
    Off <- matrix(NA_real_, nrow = dim, ncol = pop_size)
    for (k in 1:pop_size) {
      i <- sample.int(pop_size, 1); j <- sample.int(pop_size, 1)
      pa <- P[, i]; pb <- P[, j]
      child <- if (runif(1) < pcross) crossover_sbx(pa, pb, lower, upper, eta_c) else if (runif(1) < 0.5) pa else pb
      child <- mutate_poly(child, lower, upper, eta_m, pm = pmutation)
      Off[, k] <- child
    }
    off_objectives <- t(sapply(apply(Off, 2, fitness_fn), unlist)); evals <- evals + pop_size
    combined_P <- cbind(P, Off); combined_obj <- rbind(objectives, off_objectives)
    sorting <- fast_non_dominated_sort(combined_obj)
    next_idx <- c()
    for (fidx in 1:length(sorting$fronts)) {
      front <- sorting$fronts[[fidx]]
      if (length(next_idx) + length(front) <= pop_size) next_idx <- c(next_idx, front) else {
        remaining <- pop_size - length(next_idx)
        crowd <- crowding_distance(combined_obj, front)
        selected <- front[order(crowd, decreasing = TRUE)[1:remaining]]
        next_idx <- c(next_idx, selected); break
      }
    }
    P <- combined_P[, next_idx]; objectives <- combined_obj[next_idx, ]
    if (track_evals) for (i in 1:pop_size) {
      eval_history <- rbind(eval_history, data.frame(evaluations = nrow(eval_history) + 1, best_obj1 = max(objectives[,1], eval_history$best_obj1[nrow(eval_history)])))
    }
    if (verbose && g %% 10 == 0) {
      pf <- objectives[fast_non_dominated_sort(objectives)$fronts[[1]], ]
      if (is.matrix(pf)) cat(sprintf("Gen %3d | Pareto size: %d | Best obj1: %.6f\n", g, nrow(pf), max(pf[,1])))
    }
    history[[g]] <- list(generation = g, pareto_front = objectives[fast_non_dominated_sort(objectives)$fronts[[1]], ], evaluations = evals)
  }
  result <- list(pareto_front = objectives[fast_non_dominated_sort(objectives)$fronts[[1]], ],
                 final_population = P, final_objectives = objectives,
                 history = history, evaluations = evals, method = "NSGA-II")
  if (track_evals) result$eval_history <- eval_history
  result
}


```


```{r}

# Enhanced benchmark function with fixed baselines
benchmark_optimizers_fixed <- function(
  fitness_fn, dim, lower, upper,
  methods = c("EA", "PSO", "GD", "Random", "L-BFGS-B", "Nelder-Mead"),
  n_runs = 30, eval_budget = 5000,
  verbose = TRUE, seed_base = 1000,
  ...
) {
  results <- list()
  
  for (run in 1:n_runs) {
    if (verbose) cat(sprintf("\n=== Run %d/%d ===\n", run, n_runs))
    run_seed <- seed_base + run
    set.seed(run_seed)
    
    if ("EA" %in% methods) {
      if (verbose) cat("Running EA...\n")
      ea_result <- evolve_real_enhanced(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        pop_size = 50, gens = floor(eval_budget / 50),
        eval_budget = eval_budget,
        verbose = FALSE, seed = run_seed,
        track_evals = TRUE,
        ...
      )
      results[[length(results) + 1]] <- make_result_entry("EA", run, ea_result)
    }
    
    if ("PSO" %in% methods) {
      if (verbose) cat("Running PSO...\n")
      pso_result <- pso(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        swarm_size = 30, max_iter = floor(eval_budget / 30),
        eval_budget = eval_budget,
        verbose = FALSE, seed = run_seed,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("PSO", run, pso_result)
    }
    
    if ("GD" %in% methods) {
      if (verbose) cat("Running Gradient Descent...\n")
      gd_result <- gradient_descent_fd_fixed(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        eval_budget = eval_budget,
        verbose = FALSE, seed = run_seed,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("GD", run, gd_result)
    }
    
    if ("Random" %in% methods) {
      if (verbose) cat("Running Random Search...\n")
      rs_result <- bsrs(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        eval_budget = eval_budget,
        verbose = FALSE,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("Random", run, rs_result)
    }
    
    if ("L-BFGS-B" %in% methods) {
      if (verbose) cat("Running L-BFGS-B...\n")
      lb_result <- lbfgsb_baseline(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        eval_budget = eval_budget,
        seed = run_seed,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("L-BFGS-B", run, lb_result)
    }
    
    if ("Nelder-Mead" %in% methods) {
      if (verbose) cat("Running Nelder-Mead...\n")
      nm_result <- nelder_mead_baseline(
        fitness_fn = fitness_fn,
        dim = dim, lower = lower, upper = upper,
        eval_budget = eval_budget,
        seed = run_seed,
        track_evals = TRUE
      )
      results[[length(results) + 1]] <- make_result_entry("Nelder-Mead", run, nm_result)
    }
  }
  
  return(results)
}

# Enhanced analysis framework for EA evaluation study

# Performance analysis with statistical rigor
comprehensive_analysis <- function(results, alpha = 0.05) {
  
  # Extract data frame
  df <- data.frame(
    method = sapply(results, function(x) x$method),
    run = sapply(results, function(x) x$run),
    best_fit = sapply(results, function(x) x$best_fit),
    evaluations = sapply(results, function(x) x$evaluations)
  )
  
  # Basic statistics
  stats <- aggregate(best_fit ~ method, data = df, function(x) {
    c(
      n = length(x),
      mean = mean(x, na.rm = TRUE),
      median = median(x, na.rm = TRUE), 
      sd = sd(x, na.rm = TRUE),
      min = min(x, na.rm = TRUE),
      max = max(x, na.rm = TRUE),
      q25 = quantile(x, 0.25, na.rm = TRUE),
      q75 = quantile(x, 0.75, na.rm = TRUE),
      iqr = IQR(x, na.rm = TRUE)
    )
  })
  
  # Convert to more readable format

# NEW (robust to matrix-or-list)
stats_clean <- if (is.matrix(stats$best_fit)) {
  data.frame(method = stats$method, as.data.frame(stats$best_fit), row.names = NULL)
} else {
  data.frame(method = stats$method, do.call(rbind, stats$best_fit), row.names = NULL)
}

  
  methods <- unique(df$method)
  n_methods <- length(methods)
  
  # Effect sizes (Cliff's Delta) comparison matrix
  effect_matrix <- matrix(NA, n_methods, n_methods, 
                         dimnames = list(methods, methods))
  p_values <- matrix(NA, n_methods, n_methods, 
                    dimnames = list(methods, methods))
  
  for (i in 1:n_methods) {
    for (j in 1:n_methods) {
      if (i != j) {
        x <- df[df$method == methods[i], "best_fit"]
        y <- df[df$method == methods[j], "best_fit"]
        
        # Cliff's Delta effect size
        effect <- cliffs_delta(x, y)
        effect_matrix[i, j] <- effect$delta
        
        # Wilcoxon rank-sum test (non-parametric)
        test_result <- wilcox.test(x, y, alternative = "two.sided")
        p_values[i, j] <- test_result$p.value
      }
    }
  }
  
  # Multiple comparisons correction (Bonferroni)
  p_adjusted <- p_values
  n_comparisons <- sum(!is.na(p_values))
  p_adjusted[!is.na(p_values)] <- pmin(1, p_values[!is.na(p_values)] * n_comparisons)
  
  # Performance rankings
  method_ranks <- aggregate(best_fit ~ method, data = df, mean)
  method_ranks <- method_ranks[order(method_ranks$best_fit, decreasing = TRUE), ]
  method_ranks$rank <- 1:nrow(method_ranks)
  
  return(list(
    summary_stats = stats_clean,
    effect_sizes = effect_matrix,
    p_values = p_adjusted,
    p_adjusted = p_adjusted,
    rankings = method_ranks,
    sample_sizes = table(df$method)
  ))
}

# EA component importance analysis
analyze_ea_components <- function(ablation_results) {
  
  # Calculate relative performance compared to Full EA
  full_ea_performance <- mean(ablation_results[ablation_results$config == "Full EA", "best_fit"])
  
  component_analysis <- aggregate(best_fit ~ config, data = ablation_results, function(x) {
    c(
      mean = mean(x),
      sd = sd(x),
      relative_to_full = mean(x) / full_ea_performance,
      performance_drop = (full_ea_performance - mean(x)) / full_ea_performance
    )
  })
  

# NEW
component_clean <- if (is.matrix(component_analysis$best_fit)) {
  data.frame(configuration = component_analysis$config,
             as.data.frame(component_analysis$best_fit), row.names = NULL)
} else {
  data.frame(configuration = component_analysis$config,
             do.call(rbind, component_analysis$best_fit), row.names = NULL)
}

  
  # Sort by performance drop
  component_clean <- component_clean[order(component_clean$performance_drop), ]
  
  # Statistical tests comparing each variant to Full EA
  full_ea_scores <- ablation_results[ablation_results$config == "Full EA", "best_fit"]
  
  comparisons <- data.frame(
    config = character(),
    cliff_delta = numeric(),
    magnitude = character(),
    p_value = numeric(),
    significant = logical(),
    stringsAsFactors = FALSE
  )
  
  configs <- unique(ablation_results$config)
  configs <- configs[configs != "Full EA"]
  
  for (config in configs) {
    variant_scores <- ablation_results[ablation_results$config == config, "best_fit"]
    
    # Effect size
    effect <- cliffs_delta(full_ea_scores, variant_scores)
    
    # Statistical test
    test_result <- wilcox.test(full_ea_scores, variant_scores, alternative = "two.sided")
    
    comparisons <- rbind(comparisons, data.frame(
      config = config,
      cliff_delta = effect$delta,
      magnitude = effect$magnitude,
      p_value = test_result$p.value,
      significant = test_result$p.value < 0.05,
      stringsAsFactors = FALSE
    ))
  }
  
  return(list(
    component_performance = component_clean,
    statistical_comparisons = comparisons
  ))
}

# Sample efficiency analysis
analyze_sample_efficiency <- function(results) {
  
  # Extract convergence characteristics
  convergence_stats <- data.frame(
    method = character(),
    mean_convergence_eval = numeric(),
    median_convergence_eval = numeric(),
    final_performance = numeric(),
    early_performance_10pct = numeric(),
    early_performance_25pct = numeric(),
    stringsAsFactors = FALSE
  )
  
  methods <- unique(sapply(results, `[[`, "method"))
  
  for (method in methods) {
    method_results <- results[sapply(results, function(x) x$method == method)]
    
    # Only analyze methods with evaluation history
    with_history <- method_results[!sapply(method_results, function(x) is.null(x$eval_history))]
    
    if (length(with_history) > 0) {
      final_performances <- sapply(with_history, function(x) {
        if (nrow(x$eval_history) > 0) {
          tail(x$eval_history$best_so_far, 1)
        } else {
          x$best_fit
        }
      })
      
      # Performance at 10% and 25% of budget
      early_perfs_10 <- sapply(with_history, function(x) {
        if (nrow(x$eval_history) > 0) {
          max_evals <- max(x$eval_history$evaluations)
          target_eval <- 0.1 * max_evals
          idx <- which(x$eval_history$evaluations >= target_eval)[1]
          if (!is.na(idx)) x$eval_history$best_so_far[idx] else NA
        } else NA
      })
      
      early_perfs_25 <- sapply(with_history, function(x) {
        if (nrow(x$eval_history) > 0) {
          max_evals <- max(x$eval_history$evaluations)
          target_eval <- 0.25 * max_evals
          idx <- which(x$eval_history$evaluations >= target_eval)[1]
          if (!is.na(idx)) x$eval_history$best_so_far[idx] else NA
        } else NA
      })
      
      convergence_stats <- rbind(convergence_stats, data.frame(
        method = method,
        mean_convergence_eval = NA,  # Could implement convergence detection
        median_convergence_eval = NA,
        final_performance = mean(final_performances, na.rm = TRUE),
        early_performance_10pct = mean(early_perfs_10, na.rm = TRUE),
        early_performance_25pct = mean(early_perfs_25, na.rm = TRUE),
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Sample efficiency ratios
  if (nrow(convergence_stats) > 0) {
    convergence_stats$efficiency_ratio_10pct <- 
      convergence_stats$early_performance_10pct / convergence_stats$final_performance
    convergence_stats$efficiency_ratio_25pct <- 
      convergence_stats$early_performance_25pct / convergence_stats$final_performance
  }
  
  return(convergence_stats)
}

# Comprehensive reporting function
generate_report <- function(results, ablation_results = NULL, problem_name = "Unknown") {
  
  cat("=====================================\n")
  cat("EVOLUTIONARY ALGORITHM EVALUATION REPORT\n")
  cat("=====================================\n\n")
  
  cat("Problem:", problem_name, "\n")
  cat("Analysis Date:", Sys.Date(), "\n\n")
  
  # Main comparison analysis
  cat("1. PERFORMANCE COMPARISON\n")
  cat("-" %>% rep(30) %>% paste(collapse = ""), "\n")
  
  analysis <- comprehensive_analysis(results)
  
  # Print summary statistics
  print(analysis$summary_stats)
  cat("\n")
  
  # Print rankings
  cat("Performance Rankings (by mean fitness):\n")
  for (i in 1:nrow(analysis$rankings)) {
    row <- analysis$rankings[i, ]
    cat(sprintf("%d. %s: %.6f\n", row$rank, row$method, row$best_fit))
  }
  cat("\n")
  
  # Effect sizes vs best method
  best_method <- analysis$rankings$method[1]
  cat("Effect sizes vs", best_method, "(Cliff's Delta):\n")
  
  for (method in analysis$rankings$method[-1]) {
    delta <- analysis$effect_sizes[best_method, method]
    p_val <- analysis$p_adjusted[best_method, method]
    significance <- if (p_val < 0.001) "***" else if (p_val < 0.01) "**" else if (p_val < 0.05) "*" else ""
    
    cat(sprintf("  %s vs %s: δ = %.3f, p = %.4f %s\n", 
                best_method, method, delta, p_val, significance))
  }
  cat("\n")
  
  # Sample efficiency
  cat("2. SAMPLE EFFICIENCY ANALYSIS\n")
  cat("-" %>% rep(30) %>% paste(collapse = ""), "\n")
  
  efficiency <- analyze_sample_efficiency(results)
  if (nrow(efficiency) > 0) {
    print(efficiency[, c("method", "final_performance", "efficiency_ratio_10pct", "efficiency_ratio_25pct")])
  } else {
    cat("No evaluation history available for efficiency analysis.\n")
  }
  cat("\n")
  
  # EA component analysis
  if (!is.null(ablation_results)) {
    cat("3. EA COMPONENT ANALYSIS\n")
    cat("-" %>% rep(30) %>% paste(collapse = ""), "\n")
    
    comp_analysis <- analyze_ea_components(ablation_results)
    
    cat("Component Performance (relative to Full EA):\n")
    print(comp_analysis$component_performance[, c("configuration", "mean", "relative_to_full", "performance_drop")])
    cat("\n")
    
    cat("Statistical Comparisons vs Full EA:\n")
    print(comp_analysis$statistical_comparisons)
    cat("\n")
  }
  
  # Interpretation and conclusions
  cat("4. KEY FINDINGS\n")
  cat("-" %>% rep(30) %>% paste(collapse = ""), "\n")
  
  # Automatically generate insights
  ea_rank <- which(analysis$rankings$method == "EA")
  random_rank <- which(analysis$rankings$method == "Random")
  
  if (length(ea_rank) > 0 && length(random_rank) > 0) {
    if (ea_rank < random_rank) {
      ea_vs_random <- analysis$effect_sizes["EA", "Random"]
      cat(sprintf("• EA outperforms Random Search (rank %d vs %d, δ = %.3f)\n", 
                  ea_rank, random_rank, ea_vs_random))
    }
  }
  
  # Check if EA is best
  if (length(ea_rank) > 0 && ea_rank == 1) {
    cat("• EA achieves the best overall performance\n")
  } else if (length(ea_rank) > 0) {
    cat(sprintf("• EA ranks %d out of %d methods\n", ea_rank, nrow(analysis$rankings)))
  }
  
  # Gradient-based comparison
  gd_methods <- c("GD", "L-BFGS-B", "Adam")
  available_gd <- intersect(gd_methods, analysis$rankings$method)
  if (length(available_gd) > 0 && "EA" %in% analysis$rankings$method) {
    cat("• Comparison with gradient-based methods suggests", 
        if (ea_rank <= min(which(analysis$rankings$method %in% available_gd))) 
          "EA competitive or superior" else "gradient methods may be preferred")
    cat("\n")
  }
  
  cat("\n")
  
  invisible(list(
    main_analysis = analysis,
    efficiency_analysis = efficiency,
    component_analysis = if (!is.null(ablation_results)) comp_analysis else NULL
  ))
}

```

```{r}

ras <- demo_rastrigin_comparison(n_runs = 20, eval_budget = 5000)
ras

```


```{r}

ros <- demo_rosenbrock_comparison(n_runs = 20, eval_budget = 5000)
ros


```


```{r}

ml <- demo_ml_task()
ml




```


```{r}

abl <- demo_ablation(n_runs = 10, eval_budget = 3000)




```


```{r}

zdt1 <- function(x) {
  d <- length(x); f1 <- x[1]; g <- 1 + 9 * sum(x[2:d]) / (d - 1); f2 <- g * (1 - sqrt(f1 / g))
  list(f1 = -f1, f2 = -f2)  # negative for maximization framework
 }
 nsga_res <- nsga2(zdt1, dim = 10, lower = 0, upper = 1, pop_size = 100, gens = 100, seed = 42)
pf <- nsga_res$pareto_front; plot(-pf[,1], -pf[,2], pch = 19, xlab="f1", ylab="f2", main="NSGA-II Pareto (ZDT1)")




```


```{r}



# Run comprehensive comparison with fixed baselines
demo_comprehensive_analysis <- function(n_runs = 20, eval_budget = 5000) {
  
  cat("Running comprehensive EA evaluation with fixed baselines...\n")
  
  # Rastrigin comparison with all methods
  cat("\n=== RASTRIGIN FUNCTION ANALYSIS ===\n")
  rastrigin_results <- benchmark_optimizers_fixed(
    fitness_fn = rastrigin,
    dim = 10, lower = -5.12, upper = 5.12,
    methods = c("EA", "PSO", "GD", "Random", "L-BFGS-B", "Nelder-Mead"),
    n_runs = n_runs, eval_budget = eval_budget, 
    verbose = TRUE
  )
  
  # Generate comprehensive report
  ras_report <- generate_report(rastrigin_results, problem_name = "Rastrigin (d=10)")
  
  # Ablation study
  cat("\n=== EA COMPONENT ABLATION STUDY ===\n")
  ablation_data <- ablation_study(
    fitness_fn = rastrigin,
    dim = 5, lower = -5.12, upper = 5.12,
    n_runs = 15, eval_budget = 3000, 
    verbose = TRUE
  )
  
  ablation_analysis <- analyze_ea_components(ablation_data)
  
  cat("\nComponent Analysis Results:\n")
  print(ablation_analysis$component_performance)
  cat("\n")
  print(ablation_analysis$statistical_comparisons)
  
  # Visual results
  par(mfrow = c(2, 2))
  
  # Performance comparison
  df_ras <- data.frame(
    method = sapply(rastrigin_results, `[[`, "method"),
    best_fit = sapply(rastrigin_results, `[[`, "best_fit")
  )
  boxplot(best_fit ~ method, data = df_ras,
          main = "Performance Comparison (Rastrigin)",
          ylab = "Best Fitness", las = 2)
  
  # Sample efficiency
  plot_sample_efficiency(rastrigin_results, "Sample Efficiency (Rastrigin)")
  
  # Ablation results
  boxplot(best_fit ~ config, data = ablation_data,
          main = "EA Component Ablation", 
          ylab = "Best Fitness", las = 2)
  
  # Effect size heatmap (simplified)
  analysis <- comprehensive_analysis(rastrigin_results)
  methods <- rownames(analysis$effect_sizes)
  n <- length(methods)
  
  # Create a simple heatmap-style plot
  image(1:n, 1:n, analysis$effect_sizes, 
        xlab = "Method", ylab = "Method",
        main = "Effect Sizes (Cliff's Delta)",
        axes = FALSE, col = colorRampPalette(c("red", "white", "blue"))(20))
  axis(1, 1:n, methods, las = 2, cex.axis = 0.8)
  axis(2, 1:n, methods, las = 1, cex.axis = 0.8)
  
  par(mfrow = c(1, 1))
  
  return(list(
    rastrigin_results = rastrigin_results,
    rastrigin_analysis = ras_report,
    ablation_data = ablation_data,
    ablation_analysis = ablation_analysis
  ))
}

# Quick test of key findings extraction
extract_key_insights <- function(results, ablation_results = NULL) {
  
  analysis <- comprehensive_analysis(results)
  insights <- list()
  
  # EA vs Random Search
  if ("EA" %in% analysis$rankings$method && "Random" %in% analysis$rankings$method) {
    ea_rank <- which(analysis$rankings$method == "EA")
    random_rank <- which(analysis$rankings$method == "Random")
    ea_vs_random_delta <- analysis$effect_sizes["EA", "Random"]
    ea_vs_random_p <- analysis$p_adjusted["EA", "Random"]
    
    insights$ea_vs_random <- list(
      ea_better = ea_rank < random_rank,
      effect_size = ea_vs_random_delta,
      p_value = ea_vs_random_p,
      magnitude = if (abs(ea_vs_random_delta) < 0.147) "negligible"
                 else if (abs(ea_vs_random_delta) < 0.33) "small"
                 else if (abs(ea_vs_random_delta) < 0.474) "medium"
                 else "large"
    )
  }
  
  # EA overall ranking
  if ("EA" %in% analysis$rankings$method) {
    ea_rank <- which(analysis$rankings$method == "EA")
    total_methods <- nrow(analysis$rankings)
    insights$ea_ranking <- list(
      rank = ea_rank,
      total_methods = total_methods,
      is_best = ea_rank == 1,
      percentile = (total_methods - ea_rank + 1) / total_methods
    )
  }
  
  # Complexity vs performance trade-off
  simple_methods <- c("Random", "GD")
  available_simple <- intersect(simple_methods, analysis$rankings$method)
  if ("EA" %in% analysis$rankings$method && length(available_simple) > 0) {
    ea_rank <- which(analysis$rankings$method == "EA")
    simple_ranks <- sapply(available_simple, function(m) which(analysis$rankings$method == m))
    
    insights$complexity_tradeoff <- list(
      ea_beats_simple = all(ea_rank < simple_ranks),
      simple_methods_tested = available_simple,
      performance_improvement = analysis$rankings$best_fit[ea_rank] - 
                               mean(analysis$rankings$best_fit[simple_ranks])
    )
  }
  
  # Component analysis insights
  if (!is.null(ablation_results)) {
    comp_analysis <- analyze_ea_components(ablation_results)
    
    # Find most important components
    performance_drops <- comp_analysis$component_performance$performance_drop
    names(performance_drops) <- comp_analysis$component_performance$configuration
    performance_drops <- performance_drops[performance_drops > 0]  # Only drops
    
    most_important <- names(sort(performance_drops, decreasing = TRUE))[1]
    least_important <- names(sort(performance_drops))[1]
    
    insights$component_importance <- list(
      most_critical_loss = most_important,
      least_critical_loss = least_important,
      crossover_important = any(grepl("No Crossover", names(performance_drops))) && 
                           performance_drops["No Crossover"] > 0.05,
      mutation_important = any(grepl("No Mutation", names(performance_drops))) && 
                          performance_drops["No Mutation"] > 0.05,
      selection_important = any(grepl("Random Select", names(performance_drops))) && 
                           performance_drops["Random Select"] > 0.05
    )
  }
  
  return(insights)
}

# Function to generate presentation-ready summary
presentation_summary <- function(results, ablation_results = NULL, problem_name = "Test Problem") {
  
  insights <- extract_key_insights(results, ablation_results)
  analysis <- comprehensive_analysis(results)
  
  cat("PRESENTATION SUMMARY:", problem_name, "\n")
  cat("=" %>% rep(50) %>% paste(collapse = ""), "\n\n")
  
  # Main finding
  if (!is.null(insights$ea_vs_random)) {
    if (insights$ea_vs_random$ea_better) {
      cat("KEY FINDING: EA significantly outperforms random search\n")
      cat(sprintf("  - Effect size: %.3f (%s effect)\n", 
                  insights$ea_vs_random$effect_size,
                  insights$ea_vs_random$magnitude))
      cat(sprintf("  - Statistical significance: p = %.4f\n", 
                  insights$ea_vs_random$p_value))
    } else {
      cat("KEY FINDING: Random search competitive with EA\n")
      cat("  - This suggests the problem may not benefit from EA's complexity\n")
    }
  }
  cat("\n")
  
  # Overall performance
  if (!is.null(insights$ea_ranking)) {
    cat(sprintf("EA OVERALL PERFORMANCE: Rank %d of %d methods (%.0f percentile)\n",
                insights$ea_ranking$rank,
                insights$ea_ranking$total_methods,
                insights$ea_ranking$percentile * 100))
    
    if (insights$ea_ranking$is_best) {
      cat("  - EA achieves best performance among all methods tested\n")
    }
  }
  cat("\n")
  
  # Complexity justification
  if (!is.null(insights$complexity_tradeoff)) {
    if (insights$complexity_tradeoff$ea_beats_simple) {
      cat("COMPLEXITY JUSTIFICATION: EA outperforms simpler alternatives\n")
      cat(sprintf("  - Performance improvement over simple methods: %.4f\n",
                  insights$complexity_tradeoff$performance_improvement))
    } else {
      cat("COMPLEXITY CONCERN: EA does not clearly outperform simpler methods\n")
      cat("  - Consider whether added complexity is justified\n")
    }
  }
  cat("\n")
  
  # Component insights
  if (!is.null(insights$component_importance)) {
    cat("EA COMPONENT ANALYSIS:\n")
    cat(sprintf("  - Most critical component: %s\n", 
                insights$component_importance$most_critical_loss))
    
    critical_components <- c()
    if (insights$component_importance$crossover_important) 
      critical_components <- c(critical_components, "Crossover")
    if (insights$component_importance$mutation_important) 
      critical_components <- c(critical_components, "Mutation")  
    if (insights$component_importance$selection_important) 
      critical_components <- c(critical_components, "Selection")
    
    if (length(critical_components) > 0) {
      cat("  - Critical components:", paste(critical_components, collapse = ", "), "\n")
    } else {
      cat("  - No individual component shows strong importance\n")
    }
  }
  cat("\n")
  
  
  cat("PRESENTATION RECOMMENDATIONS:\n")
  cat("1. Lead with the statistical comparison vs random search\n")
  cat("2. Use effect sizes (Cliff's Delta) to quantify practical significance\n")
  cat("3. Present ablation study to show which EA parts matter\n")
  cat("4. Acknowledge both strengths and limitations of EA\n")
  cat("5. Discuss when EA might be preferred over alternatives\n")
  
  return(invisible(insights))
}

# Run the complete analysis
run_complete_study <- function() {
  
  cat("Starting complete EA evaluation study...\n")
  cat("This will take several minutes to complete.\n\n")
  
  # Run comprehensive analysis
  results <- demo_comprehensive_analysis(n_runs = 15, eval_budget = 4000)
  
  # Generate presentation summary
  cat("\n" %>% rep(3) %>% paste(collapse = ""))
  presentation_summary(
    results$rastrigin_results, 
    results$ablation_data, 
    "Rastrigin Function (d=10)"
  )
  
  return(results)
}
```



```{r}
run_complete_study()





```


```{r}

demo_comprehensive_analysis()



```